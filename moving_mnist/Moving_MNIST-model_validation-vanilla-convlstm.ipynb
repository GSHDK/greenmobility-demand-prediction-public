{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving mnist for validation of models - Vanilla convlstm\n",
    "\n",
    "The problem we are trying to solve has note been done before, to ensure our models are working as expected we introduce the moving mnist to validate our models on a dataset that has shown to work well with this type of model.\n",
    "\n",
    "Implementation based on \n",
    "https://towardsdatascience.com/video-prediction-using-convlstm-with-pytorch-lightning-27b195fd21a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from model.ConvLSTM import ConvLSTMCell\n",
    "from model.models import VanillaConvLSTM\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from datahelpers import *\n",
    "from IPython.display import clear_output\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of dim 0 of grid\n",
    "n_steps_past = 10\n",
    "n_steps_ahead = 1  # 4\n",
    "NF=30\n",
    "batch_size=6\n",
    "\n",
    "# For saving\n",
    "MODEL_NAME=\"Vanilla_conv_1_step_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path='data'\n",
    "\n",
    "train_set = MovingMNIST(root=relative_path, train=True, download=False, max_norm=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "\n",
    "\n",
    "validation_set = MovingMNIST(root=relative_path, train=False, download=False, max_norm=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=validation_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaConvLSTM(nf=NF, in_chan=1)\n",
    "CUDA=False\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda\")\n",
    "    CUDA=True\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../state_dict/model_tranied_xxx',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98791\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 31, 3, 3])\n",
      "torch.Size([120])\n",
      "torch.Size([120, 60, 3, 3])\n",
      "torch.Size([120])\n",
      "torch.Size([1, 30, 1, 3, 3])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print model parameters\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning\n",
    "\n",
    "### Verify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduceabilitu\n",
    "torch.manual_seed(3124)\n",
    "np.random.seed(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, target) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add channel and do forward pass\n",
    "# B,T,C,H,W\n",
    "\n",
    "# Asure that we get the correct number of timesteps\n",
    "assert(model(inputs.unsqueeze(2), future_seq=n_steps_ahead, cuda=CUDA).shape[2]==n_steps_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions \n",
    "\n",
    "For keeping track of learning and plotting predictions\n",
    "\n",
    "Update code to be more efficient in argument passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(pred:torch.tensor, file_prefix:str = '', file_postfix:str = '', nrow=10):\n",
    "    \"\"\"\n",
    "    Assumes tensor (b, t, c, h, w)\n",
    "    \"\"\"\n",
    "    \n",
    "    path = file_prefix\n",
    "    if not file_prefix:\n",
    "        path='moving_mnist_'\n",
    "    for b in range(pred.shape[0]):\n",
    "        torchvision.utils.save_image(make_grid(pred[b,:,:,:,:], padding=100, nrow=nrow), str(path)+ f'batchnr{b}'+str(file_postfix)+\".png\")\n",
    "        \n",
    "def plot_prediction(pred:torch.tensor,nrow=10):\n",
    "    # Remove batch\n",
    "    # b,t,c,w,h\n",
    "    if len(pred.shape)>4:\n",
    "        pred = [y for x in pred for y in x]\n",
    "    plt.imshow(np.rot90(np.transpose(make_grid(pred,nrow=nrow).numpy())),origin='lower')\n",
    "    plt.title(\"Prediction\")\n",
    "    \n",
    "def plot_output_v_target(target, outputs, nrow=10):\n",
    "    pred_eval = _join_out_ta(target, outputs)\n",
    "    plot_prediction(pred_eval, nrow=nrow)\n",
    "    \n",
    "def save_output_v_target(target:torch.tensor, outputs:torch.tensor, nrow=10, file_prefix:str = '', file_postfix:str = ''):\n",
    "    pred_eval = _join_out_ta(target, outputs)\n",
    "    save_prediction(pred_eval, nrow=nrow, file_prefix=file_prefix, file_postfix=file_postfix)\n",
    "\n",
    "def _join_out_ta(target, outputs):\n",
    "    # Example\n",
    "    # torch.cat((inputs.unsqueeze(2),model(inputs.unsqueeze(2), future_seq=10).permute(0,2,1,3,4)),dim=1)\n",
    "    \n",
    "    # assert same size except timesteps\n",
    "    assert (target[:,0,:,:,:].shape==outputs[:,0,:,:,:].shape) and (len(target.shape)==5)\n",
    "    return torch.cat((target, outputs), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, targets) in enumerate(validation_loader):\n",
    "        # Add channel\n",
    "        x = inputs.unsqueeze(2)\n",
    "        y = targets\n",
    "        if CUDA:\n",
    "            y = y.cuda()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 95% of train in epoch 29 \n",
      "Seconds since start: 3266 \n",
      "Seconds since last status: 5\n"
     ]
    }
   ],
   "source": [
    "SAVE_CHECKPOINTS=True\n",
    "\n",
    "num_epochs = 30\n",
    "itr = 0\n",
    "# Save loss for plot\n",
    "training_loss=[]\n",
    "validation_loss=[]\n",
    "\n",
    "t_L=train_loader\n",
    "\n",
    "print(\"Start Iter\")\n",
    "\n",
    "# Status parameters\n",
    "data_train_iter=75\n",
    "\n",
    "global_steps =0\n",
    "log_every=150\n",
    "\n",
    "# Monitoring\n",
    "t1=datetime.now()\n",
    "t2=datetime.now()\n",
    "for epoch in range(num_epochs):\n",
    "    # Track loss\n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    # For grid in validation set\n",
    "    print(\"Starting validation\")\n",
    "    for i, (inputs, targets) in enumerate(validation_loader):\n",
    "        # Add channel\n",
    "        x = inputs.unsqueeze(2)\n",
    "        y = targets[:,0,:,:]\n",
    "        if CUDA:\n",
    "            y = y.cuda()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        y_hat = model.forward(x, future_seq=n_steps_ahead, cuda=CUDA).squeeze()\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        # outputs shifts channel one place left\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        epoch_validation_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "    model.train()\n",
    "    # For grid in traning set\n",
    "    print(\"Starting Train\")\n",
    "    for i, (inputs,targets) in enumerate(train_loader):\n",
    "        # Status updates\n",
    "        if i%data_train_iter==0: \n",
    "            print(f\"Done with {int(i*100/len(t_L))}% of train in epoch {epoch} \\nSeconds since start: {(datetime.now()-t1).seconds} \\nSeconds since last status: {(datetime.now()-t2).seconds}\")\n",
    "            t2=datetime.now()\n",
    "        # Add channel\n",
    "        x = inputs.unsqueeze(2)\n",
    "        y = targets[:,0,:,:]\n",
    "        if CUDA:\n",
    "            y = y.cuda()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        y_hat = model.forward(x, future_seq=n_steps_ahead,cuda=CUDA).squeeze()\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        # outputs shifts channel one place left\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update loss\n",
    "        epoch_training_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        # Status updates\n",
    "        # Print loss every x steps after 1\n",
    "        if (global_steps % log_every == 0) and len(validation_loss)>0:\n",
    "            #Report status\n",
    "            print(f'Epoch: {epoch}, Global steps: {global_steps}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n",
    "            # Plot prediction\n",
    "            plt.figure(figsize=(15,20))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plot_output_v_target(inputs.cpu().unsqueeze(2), y_hat.cpu().unsqueeze(1).unsqueeze(1).detach(), nrow=11)\n",
    "            plt.subplot(2, 1, 2)\n",
    "            _epoch = np.arange(len(training_loss))\n",
    "            plt.plot(_epoch, training_loss, 'r', label='Training loss',)\n",
    "            plt.plot(_epoch, validation_loss, 'b', label='Validation loss')\n",
    "            plt.title(\"Traning and validation loos\")\n",
    "            plt.legend()\n",
    "            plt.xlabel('Epoch'), plt.ylabel('VAL')\n",
    "            plt.show()\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Save pred\n",
    "            try:\n",
    "                save_output_v_target(inputs.cpu().unsqueeze(2), y_hat.cpu().unsqueeze(1).permute(0,2,1,3,4).detach(),nrow=10, file_prefix=f'./predictions/{type(model).__name__}_pred', file_postfix=epoch)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                \n",
    "        # Step taken\n",
    "        global_steps+=1\n",
    "        \n",
    "    # Save\n",
    "    if SAVE_CHECKPOINTS:\n",
    "        model_name=f'./checkpoint_saves/{type(model).__name__}_{type(criterion).__name__}_checkpoint_{datetime.now()}'\n",
    "        # Send dict to memory\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "    # Save loss for plot\n",
    "    training_loss.append(epoch_training_loss/len(train_loader))\n",
    "    validation_loss.append(epoch_validation_loss/len(validation_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "epoch = np.arange(len(training_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
    "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
    "plt.title(\"Traning and validation loos\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('NLL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    train_eval={'validation_loss':validation_loss,\n",
    "     'traning_loss':training_loss\n",
    "    }\n",
    "    file_name=f'{type(model).__name__}_{type(criterion).__name__}_train_eval_stats_{datetime.now()}.json'\n",
    "    with open(file_name, 'w') as outfile:\n",
    "        json.dump(train_eval, outfile)\n",
    "    with open(file_name) as json_file:\n",
    "        data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=f'model_tranied_'+str(type(criterion).__name__)+'_'+MODEL_NAME+'_finish_{datetime.now()}'\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
